To be filled:
1) Kraken2
2) Nonpareil

TrimGalore

trim_galore --stringency 5 --length 75 (or 120) --quality 20 --max_n 2 --trim-n --cores 24 --paired
check under pgrep -a perl


metaspades

https://github.com/ablab/spades#sec3.2

1) Install via conda
2) Command
  a) --meta, -t, -m, -k 27,37,47,57,67,77,87,97,107,117,127 

megahit

https://github.com/voutcn/megahit

1) Install via conda environment
2) Command (27 to 127 seems preferable)
  - megahit -1 pe_1.fq -2 pe_2.fq -o out --k_min 27 --k_max 127 --k_step 10 --min-contig-len 1000 -t 96

metaCarvel

https://github.com/marbl/MetaCarvel/wiki/5.-Interpreting-the-output

1) Install as per github page
  - conda activate py2 (install everything under python 2 environment)
  - Check samtools, bedtools, numpy, bowtie2 through conda
  - pip install networkx==1.10
2) Prepare data using bowtie2 and samtools as shown
    - bowtie2-build --threads 96 contigs.fasta idx
    - bowtie2 --threads 96 -x idx -U first.fastq.gz | samtools view -bS -@ 96 - | samtools sort -@ 96 - -o alignment_1.bam (do the same for the R2 lib)
    - samtools merge -@ 96 alignment_total.bam alignment_1.bam alignment_2.bam
    - samtools sort -@ 96 -n alignment_total.bam -o alignment.bam
3) Command
  - python <<*Carvel/run.py>> -a <<*83a/*127/*.fa>> -m <<*83a/*bowtie/alignment.bam>> -d <<MBS1383mega127filcarvrk>> -r true -l 1000
  - Note: always keep -r and -k true. -l 1000 for contigs above 1000 only for binning 

minCED 

https://github.com/ctSkennerton/minced

1) Install minCED through conda
2) Command
  - minced -minNR 2 (or 3) -minRL 16 -maxRL 64 -minSL 8 -maxSL 72 <<.fa>> <<.txt>>

cctyper

https://github.com/Russel88/CRISPRCasTyper/blob/master/bin/cctyper

1) Install cctyper as above link specified, activate cctyper environment
2) For chromosomes: cctyper <<input fasta>> <<output file directory name>> --prodigal single --circular -t <<thread number>> --keep_tmp 
For scaffold/contig: cctyper <<input fasta>> <<output file directory name>> --prodigal meta -t <<thread number>> --keep_tmp
For meta: similar to scaffold/contig


For binning:

1) Preparation (alignment)

bowtie2-build --threads  scaffold.fasta idx
bowtie2 --threads 96 -x idx -1 first.fastq.gz -2 first.fastq.gz -S *.sam

  (the ff 2 commands are for maxbin2)
  pileup.sh in=megahit.sam  out=cov.txt
  awk '{print $1"\t"$5}' cov.txt | grep -v '^#' > abundance.txt
  
samtools view -b -S -@ 96 -o *.bam *.sam (or if header missing samtools view -bT MBS1383metacarvel.fa MBS1383aln.sam > MBS1383aln.bam)
samtools sort -@ 96 MBS1384aln.bam -o MBS1384alnsorted (samtools flagstat bwaOutput.bam - to calculate for % reads aligned)
samtools index *sorted.bam
samtools flagstat sortedoutput.bam (report the alignment)

jgi_summarize_bam_contig_depths --outputDepth depth.txt *.bam

2) Preparation and running concoct

cut_up_fasta.py original_contigs.fa -c 10000 -o 0 --merge_last -b contigs_10K.bed > contigs_10K.fa
concoct_coverage_table.py contigs_10K.bed mapping/Sample*.sorted.bam > coverage_table.tsv (make sure sorted.bam.bai is available in the same folder at this point)
concoct --composition_file contigs_10K.fa --coverage_file coverage_table.tsv -t 96 -b concoct_output/
merge_cutup_clustering.py concoct_output/clustering_gt1000.csv > concoct_output/clustering_merged.csv
mkdir concoct_output/fasta_bins
extract_fasta_bins.py original_contigs.fa concoct_output/clustering_merged.csv --output_path concoct_output/fasta_bins (make sure you have mkdir)

3) Running the bins (metabat2 and maxbin2)

metabat2 -i MBS1383_metacarvel.fa -a MBS1383_metabat2_depth.txt -o MBS1383_metabat
run_MaxBin.pl -contig scaffold.fa -abund abundance.txt -out myout


Bins Merging

metawrap bin_refinement -o MBS1384_binmerged -t 64 -A *initialbins/metabat2_bins/ -B *initialbins/maxbin2_bins/ -C *initialbins/concoct_bins/ -c 50 -x 10

column -t metawrap_50_10_bins.stats | awk '{print $1, $2, $3, $2-(5*$3)}' | awk '$2>50 && $3<10 && $4>50' | wc -l (to check how many bins are with good quality)


RefineM

1) Refine based on composition

refinem scaffold_stats -c 96 --genome_ext .fa MBS1384metacarvel.fa *merged/metawrap_50_5_bins MBS1384refinem MBS1384alnsorted.bam (make sure that the *.bam and *.bam.bai is in the same directory)
      - output scaffold_stats.tsv and 3 more files
refinem outliers <stats_output_dir>/scaffold_stats.tsv <outlier_output_dir>
      - output outliers.tsv
refinem filter_bins --genome_ext .fa *merged/*5_bins *refinem/outliers.tsv *product1

2) Refine based on taxonomy

refinem call_genes --genome_ext .fa -c 96 *_1 MBS1384refinem_2 (use the bins refined based on composition)
refinem taxon_profile -c 96 MBS1384_refinem_genes <stats_output_dir>/scaffold_stats.tsv <reference_db> <reference_taxonomy> <taxon_profile_output_dir> (make sure databases are in the same working directory, weird)
refinem taxon_filter -c 40 <taxon_profile_dir> taxon_filter.tsv
refinem filter_bins --genome_ext .fa *product1 *temp3/taxon_filter.tsv MBS1384_refinem_product2 (check the folder if both filtered and unfiltered bins, get filtered ones)

Bin_Reassembly
metawrap reassemble_bins --parallel -o MBS1383_binreassembled -1 *_1.fastq -2 *_2.fastq -t 96 -m 824 -c 50 -x 5 -b *product2 (bins from refinem stage 2) - note: too damn long

CheckM
1) Install
https://github.com/Ecogenomics/CheckM/wiki
2) 


16S rRNA detection and analysis

https://github.com/christophertbrown/bioscripts

1) Install as per github
  - Install infernal and SSU-Align
  - Download Database from their github and upload it to your system
  - Create the environment export ssucmdb="databases/ssu-align-0p1.1.cm"
2) Command
  -  16SfromHMM.py -f <<*84a/*carvrk/scaffolds.fa>> -m -t 16 > <<MBS1384carvrk16S.fa>>
3) Analysis
  - Download the .fa file
  - Silva ACT website. Enable Sina Search and Classify. 
  - Enable SILVA taxonomic classification (LCA's)
4) Report
  - Open .csv in R studio; be sure all libraries and dependencies there
  - E.g. Keep only scaffold ID, % identity, length of bp, taxonomy
  
        silva1383 <- read.csv("a.csv", head = TRUE, sep = ";")
        silva1383 <- silva1383[c(3,9,15,21)]

Libraries (for phylogeny and other CRISPR stuff)

1) Download all "complete genomes", chromosomes, scaffolds, contigs from assembly under bacteria and archaea (For bacteria scaffolds and contigs, 2015-01-01 and above)
2) Download meta txid 256318, 410656, 410657


CCtyper

1) Install (conda create -n cctyper -c conda-forge -c bioconda -c russel88 cctyper
conda activate cctyper)
2) cctyper assembly.fa my_output --prodigal meta (or single) --no_plot --keep_tmp --skip_check -t 96


Plass

trim_galore --stringency 5 --length 120 --quality 20 --max_n 2 --trim-n --cores 8 â€“paired MBS1384R1_1.fastq.gz MBS1384R1_2.fastq.gz
zcat MBS1384R1_1_trimming_min120.fastq.gz MBS1384R1_2_trimming_min120.fastq.gz | seqkit sample -p 0.5 -o MBS1384R1_12_min120_max10GB.fastq.gz -j 64 (-p parameters should have a final dataset of 20GB)
plass assemble *84/*_1*trimmed.fq.gz *84/*_2*trimmed.fq.gz MBS1384_plass MBS1384_plass_tmp --threads 64 --min-length 40 (do pullseq if needed)
pullseq for 100 aa only
seqkit split and seqkit fx2tsv 

EMBOSS (backtranseq)

backtranseq -cfile Eecoli.cut


