To be filled:
1) Kraken2
2) Nonpareil

metaspades

https://github.com/ablab/spades#sec3.2

1) Install via conda
2) Command
  a) --meta, -t, -m, -k 27,37,47,57,67,77,87,97,107,117,127 

megahit

https://github.com/voutcn/megahit

1) Install via conda environment
2) Command (27 to 127 seems preferable)
  - megahit -1 pe_1.fq -2 pe_2.fq -o out --k_min 27 --k_max 127 --k_step 10 --min-contig-len 1000

metaCarvel

https://github.com/marbl/MetaCarvel/wiki/5.-Interpreting-the-output

1) Install as per github page
  - conda activate py2 (install everything under python 2 environment)
  - Check samtools, bedtools, numpy, bowtie2 through conda
  - pip install networkx==1.10
2) Prepare data using bowtie2 and samtools as shown
3) Command
  - python <<*Carvel/run.py>> -a <<*83a/*127/*.fa>> -m <<*83a/*bowtie/alignment.bam>> -d <<MBS1383mega127filcarvrk>> -r true -l 1000 -k true
  - Note: always keep -r and -k true. -l 1000 for contigs above 1000 only for binning 

minCED 

https://github.com/ctSkennerton/minced

1) Install minCED through conda
2) Command
  - minced -minNR 2 (or 3) -minRL 16 -maxRL 64 -minSL 8 -maxSL 72 <<.fa>> <<.txt>>

cctyper

https://github.com/Russel88/CRISPRCasTyper/blob/master/bin/cctyper

1) Install cctyper as above link specified, activate cctyper environment
2) For chromosomes: cctyper <<input fasta>> <<output file directory name>> --prodigal single --circular -t <<thread number>> --keep_tmp 
For scaffold/contig: cctyper <<input fasta>> <<output file directory name>> â€“-prodigal meta -t <<thread number>> --keep_tmp
For meta: similar to scaffold/contig

Post-scaffold

1) For reporting alignment, report using bowtie2. Actually bwa is fine.

Binning

1) metawrap install
2) do maxbin2 and metabat2 from metawrap (metawrap binning -o INITIAL_BINNING -t 96 -a ASSEMBLY/final_assembly.fasta --metabat2 --maxbin2 --run-checkm CLEAN_READS/ERR*fastq)
3) Do concoct separately (https://onestopdataanalysis.com/binning/ and the github page) using bwa mem; use bowtie2 just for alignment statistics

For concoct:

1) Preparation (alignment)

bwa index original_contigs.fa
bwa mem -t 96 -o MBS1384aln.sam MBS1384metacarvel.fa MBS1384R1_1.fastq MBS1384R1_2.fastq
samtools view -b -S -@ 96 -o *.bam *.sam (or if header missing samtools view -bT MBS1383metacarvel.fa MBS1383aln.sam > MBS1383aln.bam)
samtools sort -@ 96 MBS1384aln.bam MBS1384alnsorted (samtools flagstat bwaOutput.bam - to calculate for % reads aligned)
samtools index *sorted.bam

2) Preparation (data)

cut_up_fasta.py original_contigs.fa -c 10000 -o 0 --merge_last -b contigs_10K.bed > contigs_10K.fa
concoct_coverage_table.py contigs_10K.bed mapping/Sample*.sorted.bam > coverage_table.tsv (make sure sorted.bam.bai is available in the same folder at this point)
concoct --composition_file contigs_10K.fa --coverage_file coverage_table.tsv -t 96 -b concoct_output/
merge_cutup_clustering.py concoct_output/clustering_gt1000.csv > concoct_output/clustering_merged.csv
mkdir concoct_output/fasta_bins
extract_fasta_bins.py original_contigs.fa concoct_output/clustering_merged.csv --output_path concoct_output/fasta_bins (make sure you have mkdir)

Bins Merging

metawrap bin_refinement -o MBS1384_binmerged -t 96 -A *initialbins/metabat2_bins/ -B *initialbins/maxbin2_bins/ -C *initialbins/concoct_bins/ -c 50 -x 10

RefineM

1) Refine based on composition

refinem scaffold_stats -c 96 --genome_ext .fa MBS1384metacarvel.fa *merged/metawrap_50_5_bins MBS1384refinem MBS1384alnsorted.bam (make sure that the *.bam and *.bam.bai is in the same directory)
      - output scaffold_stats.tsv and 3 more files
refinem outliers <stats_output_dir>/scaffold_stats.tsv <outlier_output_dir>
      - output outliers.tsv
refinem filter_bins --genome_ext .fa --modified_only *merged/*5_bins *refinem/outliers.tsv *refinem

2) Refine based on taxonomy

refinem call_genes --genome_ext .fa -c 96 *_1 MBS1384refinem_2 (use the bins refined based on composition)



16S rRNA detection and analysis

https://github.com/christophertbrown/bioscripts

1) Install as per github
  - Install infernal and SSU-Align
  - Download Database from their github and upload it to your system
  - Create the environment export ssucmdb="databases/ssu-align-0p1.1.cm"
2) Command
  -  16SfromHMM.py -f <<*84a/*carvrk/scaffolds.fa>> -m -t 16 > <<MBS1384carvrk16S.fa>>
3) Analysis
  - Download the .fa file
  - Silva ACT website. Enable Sina Search and Classify. 
  - Enable SILVA taxonomic classification (LCA's)
4) Report
  - Open .csv in R studio; be sure all libraries and dependencies there
  - E.g. Keep only scaffold ID, % identity, length of bp, taxonomy
  
        silva1383 <- read.csv("a.csv", head = TRUE, sep = ";")
        silva1383 <- silva1383[c(3,9,15,21)]

Libraries (for phylogeny and other CRISPR stuff)

1) Download all "complete genomes", chromosomes, scaffolds, contigs from assembly under bacteria and archaea (For bacteria scaffolds and contigs, 2015-01-01 and above)
2) Download meta txid 256318, 410656, 410657


CCtyper

1) Install (conda create -n cctyper -c conda-forge -c bioconda -c russel88 cctyper
conda activate cctyper)
2) cctyper assembly.fa my_output --prodigal meta (or single) --no_plot --keep_tmp --skip_check -t 96




